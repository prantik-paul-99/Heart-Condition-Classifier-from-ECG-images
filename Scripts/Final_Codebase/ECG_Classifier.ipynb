{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Connect to Google Drive**","metadata":{"_uuid":"5eae95be-25c1-44ca-9c76-d075cceafcab","_cell_guid":"532f6fd0-62f9-48a4-86c2-66d2084d268b","trusted":true}},{"cell_type":"code","source":"!pip install gdown\n\n# 64 x 64\n!gdown --folder 'https://drive.google.com/drive/folders/19MU_bHOWIPvCrcvHTBzHkvLbAFWt8ZOA'\n\n%cd /kaggle/working/64_64_gray_invert_dilate\n%ls","metadata":{"_uuid":"2687c10b-2a0f-4e76-8fe0-984b63a133a7","_cell_guid":"d0337d24-4dac-42e5-908f-8c6b7fd856ac","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T14:55:21.287323Z","iopub.execute_input":"2023-02-27T14:55:21.288697Z","iopub.status.idle":"2023-02-27T14:55:55.380288Z","shell.execute_reply.started":"2023-02-27T14:55:21.288584Z","shell.execute_reply":"2023-02-27T14:55:55.379154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Load Data**","metadata":{"_uuid":"48fcd9a2-c156-4c2f-866e-8f32ce542121","_cell_guid":"20ea6d61-5ad0-4008-9fee-88dab5af2c46","trusted":true}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm","metadata":{"_uuid":"58ea07f5-6617-4b2e-a607-59321ec90a07","_cell_guid":"76b20cb4-f5c6-4fd6-964c-f232b354616b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T14:55:55.382936Z","iopub.execute_input":"2023-02-27T14:55:55.383778Z","iopub.status.idle":"2023-02-27T14:55:55.390146Z","shell.execute_reply.started":"2023-02-27T14:55:55.383739Z","shell.execute_reply":"2023-02-27T14:55:55.388742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_mini_batch(input_X, label, batch_size):\n    for i in range(0, len(input_X), batch_size):\n        yield input_X[i: i + batch_size], label[i: i + batch_size]\n\ndef get_mini(input_X, batch_size):\n    for i in range(0, len(input_X), batch_size):\n        yield input_X[i: i + batch_size]","metadata":{"_uuid":"a5d6aa7b-9fee-42ec-ab82-8843a59c576d","_cell_guid":"07359d69-2aef-4390-930b-dde085a12601","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T14:55:55.392083Z","iopub.execute_input":"2023-02-27T14:55:55.392516Z","iopub.status.idle":"2023-02-27T14:55:55.400706Z","shell.execute_reply.started":"2023-02-27T14:55:55.392481Z","shell.execute_reply":"2023-02-27T14:55:55.399787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_images_from_npy(divide=13):\n    covid_images = np.load('./covid.npy', allow_pickle=True)\n    hb_images = np.load('./hb.npy', allow_pickle=True)\n    mi_images = np.load('./mi.npy', allow_pickle=True)\n    normal_images = np.load('./normal.npy', allow_pickle=True)\n    pmi_images = np.load('./pmi.npy', allow_pickle=True)\n\n\n    # covid - 0\n    # hb - 1\n    # mi - 2\n    # normal - 3\n    # pmi - 4\n\n    # fill labels 0 for covid, 1 for hb, 2 for mi, 3 for normal, 4 for pmi\n    labels = [0] * (len(covid_images) // divide)\n    labels.extend([1] * (len(hb_images) // divide))\n    labels.extend([2] * (len(mi_images) // divide))\n    labels.extend([3] * (len(normal_images) // divide))\n    labels.extend([4] * (len(pmi_images) // divide))\n\n    images = np.concatenate((covid_images, hb_images, mi_images, normal_images, pmi_images), axis=0)\n\n    images = np.array(images)\n    labels = np.array(labels)\n\n    return images, labels\n\n\ndef take_12_leads(data, labels):\n    images = []\n    new_labels = []\n\n    for X, y in get_mini_batch(data, labels, 13):\n        X = np.delete(X, 4, axis=0)\n        y = np.delete(y, 4, axis=0)\n        images.extend(X)\n        new_labels.extend(y)\n\n    images = np.array(images)\n    new_labels = np.array(new_labels)\n    \n    return images, new_labels\n\ndef combine_leads_of_image(data, exclude_last=False):\n  \n    # store each 13 lead images in a list of 13*28*28 arrays\n    images = []\n\n    for X in get_mini(data, 13):\n        if exclude_last:\n            X = np.delete(X, 4, axis=0)\n        images.append(X)\n\n    images = np.array(images)\n    return images\n\n\ndef stack_images(images):\n    stacked_images = np.empty((images.shape[0],images.shape[1]*images.shape[2],images.shape[3]))\n\n    for i in range(images.shape[0]):\n        stacked_parts = np.vstack(images[i])\n        stacked_images[i] = stacked_parts\n    \n    return stacked_images","metadata":{"_uuid":"ce213be4-30d7-4982-802b-879cbb7daccb","_cell_guid":"2da33c0c-38e1-4835-8eaa-4b521ebf6ac7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T14:55:55.402392Z","iopub.execute_input":"2023-02-27T14:55:55.402839Z","iopub.status.idle":"2023-02-27T14:55:55.417580Z","shell.execute_reply.started":"2023-02-27T14:55:55.402806Z","shell.execute_reply":"2023-02-27T14:55:55.416436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' \ndivide = 1 for 35698 labels\ndivide = 13 for 2746 labels\n'''\nimages, labels = load_images_from_npy(divide=13)\nprint(images.shape, labels.shape, images[0].shape)\n\n'''combine 13 leads'''\nimages = combine_leads_of_image(images, exclude_last=False)\nprint(images.shape)","metadata":{"_uuid":"e96baaf2-a25b-4a08-8bf8-e262bc525872","_cell_guid":"89854c61-869f-4090-96bb-11848ed155ab","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T14:55:55.421009Z","iopub.execute_input":"2023-02-27T14:55:55.421403Z","iopub.status.idle":"2023-02-27T14:55:55.641430Z","shell.execute_reply.started":"2023-02-27T14:55:55.421369Z","shell.execute_reply":"2023-02-27T14:55:55.640333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from PIL import Image, ImageOps, ImageFilter\n# from IPython.display import display\n\n# def build_image_from_array(img_arr):\n#     image = Image.fromarray(img_arr).convert('1')\n#     display(image)\n\n# build_image_from_array(images[0][4])","metadata":{"_uuid":"adbb3c13-74d9-4890-9d99-4f7cb2a77a36","_cell_guid":"6ed45952-f8b3-4c8f-a510-d107c31be554","collapsed":false,"execution":{"iopub.status.busy":"2023-02-27T14:55:55.642783Z","iopub.execute_input":"2023-02-27T14:55:55.643421Z","iopub.status.idle":"2023-02-27T14:55:55.649009Z","shell.execute_reply.started":"2023-02-27T14:55:55.643384Z","shell.execute_reply":"2023-02-27T14:55:55.647951Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_val_split(images, labels, split_factor_train=0.8, split_factor_test=0.9):\n    random_indices = np.random.choice(len(images), len(images), replace=False)\n    training_data_full = images[random_indices]\n    training_label_full = labels[random_indices]\n\n    split_index_train = int(split_factor_train * len(training_data_full))\n    split_index_test = int(split_factor_test * len(training_data_full))\n\n    training_data = training_data_full[:split_index_train]\n    training_label = training_label_full[:split_index_train]\n\n    validation_data = training_data_full[split_index_train : split_index_test]\n    validation_label = training_label_full[split_index_train : split_index_test]\n\n    test_data = training_data_full[split_index_test :]\n    test_label = training_label_full[split_index_test :]\n\n    return training_data, training_label, validation_data, validation_label, test_data, test_label","metadata":{"_uuid":"210255c6-2d68-47e1-8c5e-0ea491de0a8d","_cell_guid":"308a1915-fdff-48fa-b214-5ae3eca21af6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T14:55:55.650733Z","iopub.execute_input":"2023-02-27T14:55:55.651148Z","iopub.status.idle":"2023-02-27T14:55:55.660828Z","shell.execute_reply.started":"2023-02-27T14:55:55.651111Z","shell.execute_reply":"2023-02-27T14:55:55.659804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Build Model**","metadata":{"_uuid":"f8b27b7a-6757-4303-9912-c54d9026ec27","_cell_guid":"836d561e-db2f-49a5-8d00-1a8335b24af0","trusted":true}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport torch.optim.lr_scheduler as lr_scheduler","metadata":{"_uuid":"e1302f15-ab66-4c7e-a07b-a8d1af7cca98","_cell_guid":"a1b92b4d-311f-4646-b3f4-df829a39543d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T14:55:55.662359Z","iopub.execute_input":"2023-02-27T14:55:55.662791Z","iopub.status.idle":"2023-02-27T14:55:59.060295Z","shell.execute_reply.started":"2023-02-27T14:55:55.662659Z","shell.execute_reply":"2023-02-27T14:55:59.059309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **CNN_with_Attention**","metadata":{"_uuid":"6fa48793-39a8-4c71-b831-864a1d641f32","_cell_guid":"ddd8f592-26d4-4a4c-b5d8-5cbcd1c028de","trusted":true}},{"cell_type":"code","source":"class ProjectorBlock(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(ProjectorBlock, self).__init__()\n        self.op = nn.Conv2d(in_channels=in_features, out_channels=out_features,\n            kernel_size=1, padding=0, bias=False)\n\n    def forward(self, x):\n        return self.op(x)\n\n\nclass SpatialAttn(nn.Module):\n    def __init__(self, in_features, normalize_attn=True):\n        super(SpatialAttn, self).__init__()\n        self.normalize_attn = normalize_attn\n        self.op = nn.Conv2d(in_channels=in_features, out_channels=1,\n            kernel_size=1, padding=0, bias=False)\n\n    def forward(self, l, g):\n        N, C, H, W = l.size()\n        c = self.op(l+g) # (batch_size,1,H,W)\n        if self.normalize_attn:\n            a = F.softmax(c.view(N,1,-1), dim=2).view(N,1,H,W)\n        else:\n            a = torch.sigmoid(c)\n        g = torch.mul(a.expand_as(l), l)\n        if self.normalize_attn:\n            g = g.view(N,C,-1).sum(dim=2) # (batch_size,C)\n        else:\n            g = F.adaptive_avg_pool2d(g, (1,1)).view(N,C)\n        return c.view(N,1,H,W), g\n\n    \n\nclass AttnVGG(nn.Module):\n    def __init__(self, sample_size, num_classes, attention=True, normalize_attn=True, init_weights=True):\n        super(AttnVGG, self).__init__()\n        # conv blocks\n        self.conv1 = self._make_layer(13, 64, 2)\n        self.conv2 = self._make_layer(64, 128, 2)\n        self.conv3 = self._make_layer(128, 256, 3)\n        self.conv4 = self._make_layer(256, 512, 3)\n        self.conv5 = self._make_layer(512, 512, 3)\n        self.conv6 = self._make_layer(512, 512, 2, pool=True)\n        self.dense = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=int(sample_size/32), padding=0, bias=True)\n        # attention blocks\n        self.attention = attention\n        if self.attention:\n            self.projector = ProjectorBlock(256, 512)\n            self.attn1 = SpatialAttn(in_features=512, normalize_attn=normalize_attn)\n            self.attn2 = SpatialAttn(in_features=512, normalize_attn=normalize_attn)\n            self.attn3 = SpatialAttn(in_features=512, normalize_attn=normalize_attn)\n        # final classification layer\n        if self.attention:\n            self.classify = nn.Linear(in_features=512*3, out_features=num_classes, bias=True)\n        else:\n            self.classify = nn.Linear(in_features=512, out_features=num_classes, bias=True)\n        # if init_weights:\n        #     self._initialize_weights()\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        l1 = self.conv3(x)\n        x = F.max_pool2d(l1, kernel_size=2, stride=2, padding=0)\n        l2 = self.conv4(x)\n        x = F.max_pool2d(l2, kernel_size=2, stride=2, padding=0)\n        l3 = self.conv5(x)\n        x = F.max_pool2d(l3, kernel_size=2, stride=2, padding=0)\n        x = self.conv6(x)\n        g = self.dense(x) # batch_sizex512x1x1\n\n        # attention\n        if self.attention:\n            c1, g1 = self.attn1(self.projector(l1), g)\n            c2, g2 = self.attn2(l2, g)\n            c3, g3 = self.attn3(l3, g)\n            g = torch.cat((g1,g2,g3), dim=1) # batch_sizex3C\n            # classification layer\n            x = self.classify(g) # batch_sizexnum_classes\n        else:\n            c1, c2, c3 = None, None, None\n            x = self.classify(torch.squeeze(g))\n        \n        return x\n\n    def _make_layer(self, in_features, out_features, blocks, pool=False):\n        layers = []\n        for i in range(blocks):\n            conv2d = nn.Conv2d(in_channels=in_features, out_channels=out_features, kernel_size=3, padding=1, bias=False)\n            layers += [conv2d, nn.BatchNorm2d(out_features), nn.ReLU(inplace=True)]\n            in_features = out_features\n            if pool:\n                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        return nn.Sequential(*layers)\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)","metadata":{"_uuid":"4e4b6e88-63b9-49c1-b874-6013628add00","_cell_guid":"47f0ef00-5f57-4254-95d9-700a599f00f6","collapsed":false,"execution":{"iopub.status.busy":"2023-02-27T14:55:59.062018Z","iopub.execute_input":"2023-02-27T14:55:59.063075Z","iopub.status.idle":"2023-02-27T14:55:59.087672Z","shell.execute_reply.started":"2023-02-27T14:55:59.063039Z","shell.execute_reply":"2023-02-27T14:55:59.086808Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **LSTM_with_Attention**","metadata":{"_uuid":"50304315-5a94-494b-a3f8-7f6036ff72b5","_cell_guid":"5a7adcb2-6b32-44bb-b68f-da19d9d852bd","trusted":true}},{"cell_type":"code","source":"class TemporalAttn(nn.Module):\n    def __init__(self, hidden_size):\n        super(TemporalAttn, self).__init__()\n        self.hidden_size = hidden_size\n        self.fc1 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n        self.fc2 = nn.Linear(self.hidden_size*2, self.hidden_size, bias=False)\n\n    def forward(self, hidden_states):\n        score_first_part = self.fc1(hidden_states)\n        h_t = hidden_states[:,-1,:]\n        score = torch.bmm(score_first_part, h_t.unsqueeze(2)).squeeze(2)\n        attention_weights = F.softmax(score, dim=1)\n        context_vector = torch.bmm(hidden_states.permute(0,2,1), attention_weights.unsqueeze(2)).squeeze(2)\n        pre_activation = torch.cat((context_vector, h_t), dim=1)\n        attention_vector = self.fc2(pre_activation)\n        attention_vector = torch.tanh(attention_vector)\n\n        return attention_vector, attention_weights\n\n    \nclass AttnLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers):\n        super(AttnLSTM, self).__init__()\n        self.flatten = nn.Flatten(start_dim=1)\n        self.lstm = nn.LSTM(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True)\n        self.attn = TemporalAttn(hidden_size=hidden_size)\n        self.fc = nn.Linear(hidden_size, 5)\n\n    def forward(self, x):\n        x, (h_n, c_n) = self.lstm(x)\n        x, weights = self.attn(x)\n        x = self.fc(x)\n        return x","metadata":{"_uuid":"690fd590-5a38-458b-a5da-97890b3a243f","_cell_guid":"57863a85-172c-41ab-b18a-a0b3737f57be","collapsed":false,"execution":{"iopub.status.busy":"2023-02-27T14:55:59.089216Z","iopub.execute_input":"2023-02-27T14:55:59.089917Z","iopub.status.idle":"2023-02-27T14:55:59.107338Z","shell.execute_reply.started":"2023-02-27T14:55:59.089881Z","shell.execute_reply":"2023-02-27T14:55:59.106375Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Time_Distributed_CNN**","metadata":{"_uuid":"18bf0265-09e3-4753-b985-feca67d68486","_cell_guid":"062342bc-a0bb-4f32-820c-8128f05c1497","trusted":true}},{"cell_type":"code","source":"class TimeDistributed(nn.Module):\n    def __init__(self, module, time_steps, batch_first=False):\n        super(TimeDistributed, self).__init__()\n        self.module = module\n        \n        self.layers = nn.ModuleList([module for i in range(time_steps)])\n        \n        self.time_steps = time_steps\n        self.batch_first = batch_first\n\n    def forward(self, x):\n\n        batch_size, time_steps, channels, H, W = x.size()\n        output = torch.tensor([]).to(\"cuda:0\")\n        \n        for i in range(time_steps):\n            output_t = self.layers[i](x[:, i, :, :, :])\n            output_t  = output_t.unsqueeze(1)\n            output = torch.cat((output, output_t), 1)\n        \n        return output\n\nclass Time_Distributed_CNN_Network(nn.Module):\n    def __init__(self):\n        super(Time_Distributed_CNN_Network, self).__init__()\n\n        self.time_steps = 8\n        self.extraction_layers = nn.Sequential(\n            TimeDistributed(module=nn.LazyConv2d(out_channels=64, kernel_size=3, padding=1), \n                            time_steps=self.time_steps),\n            nn.ReLU(),\n            TimeDistributed(module=nn.MaxPool2d(kernel_size=2, stride=2), time_steps=self.time_steps),\n            \n            TimeDistributed(module=nn.LazyConv2d(out_channels=128, kernel_size=3, padding=1), \n                            time_steps=self.time_steps),\n            nn.ReLU(),\n            TimeDistributed(module=nn.MaxPool2d(kernel_size=2, stride=2), time_steps=self.time_steps),\n        )\n        \n        \n        self.classification_layers = nn.Sequential(\n            nn.Flatten(start_dim=1),\n            nn.LazyLinear(64),\n            nn.ReLU(),\n            nn.LazyLinear(5),\n            nn.LogSoftmax(dim=1)\n        )\n\n\n    def forward(self, input_X):\n        \n        for layer in self.extraction_layers:\n            input_X = layer(input_X)\n    \n        for layer in self.classification_layers:\n            input_X = layer(input_X)\n\n        return input_X","metadata":{"_uuid":"25c8127b-bffe-4448-9f15-de620143843d","_cell_guid":"b67c047b-f782-487f-8c7f-f05d63168a1b","collapsed":false,"execution":{"iopub.status.busy":"2023-02-27T14:55:59.108634Z","iopub.execute_input":"2023-02-27T14:55:59.109076Z","iopub.status.idle":"2023-02-27T14:55:59.127392Z","shell.execute_reply.started":"2023-02-27T14:55:59.109041Z","shell.execute_reply":"2023-02-27T14:55:59.126146Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **CNN & LSTM_Attention Hybrid**","metadata":{"_uuid":"d0812487-800a-4281-999b-158a5c8ff287","_cell_guid":"0d8448cb-9174-45ca-b934-fef54cf12170","trusted":true}},{"cell_type":"code","source":"class HybridNetwork(nn.Module):\n    def __init__(self):\n        super(HybridNetwork, self).__init__()\n\n        self.extraction_layers = nn.Sequential(\n            nn.LazyConv2d(out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.LazyConv2d(out_channels=128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            nn.Flatten(start_dim=1, end_dim=2),\n        )\n        \n#         self.lstm = nn.GRU(input_size=16, hidden_size=10, num_layers=1, batch_first=True, \n#                                 dropout=0.25, bidirectional=False)\n        self.attn = AttnLSTM(input_size=16, hidden_size=128, num_layers=1)\n        \n        self.classification_layers = nn.Sequential(\n            nn.Flatten(start_dim=1),\n            nn.LazyLinear(64),\n            nn.ReLU(),\n            nn.LazyLinear(5),\n            nn.LogSoftmax(dim=1)\n        )\n\n\n    def forward(self, input_X):\n        \n        for layer in self.extraction_layers:\n            input_X = layer(input_X)\n        \n#         input_X, (h, c) = self.lstm(input_X) #lstm\n#         input_X, h = self.lstm(input_X) #gru\n        \n#         print('before attn', input_X.shape)\n        input_X = self.attn(input_X)\n        \n        for layer in self.classification_layers:\n            input_X = layer(input_X)\n\n        return input_X","metadata":{"_uuid":"753cabcd-b4a5-4247-8c9a-5d999ef3644e","_cell_guid":"8cdd20dd-2b88-48fb-9eba-a43318a6053f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T14:55:59.128733Z","iopub.execute_input":"2023-02-27T14:55:59.129154Z","iopub.status.idle":"2023-02-27T14:55:59.145516Z","shell.execute_reply.started":"2023-02-27T14:55:59.129119Z","shell.execute_reply":"2023-02-27T14:55:59.144487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **CNN**","metadata":{"_uuid":"e2803112-feea-4424-a619-dfb3e66841cf","_cell_guid":"756587a9-75b4-4ed4-9b35-6b52a87c047b","trusted":true}},{"cell_type":"code","source":"class CNNNetwork(nn.Module):\n    def __init__(self):\n        super(CNNNetwork, self).__init__()\n\n        self.extraction_layers = nn.Sequential(\n            nn.LazyConv2d(out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.LazyConv2d(out_channels=128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.classification_layers = nn.Sequential(\n            nn.Flatten(start_dim=1),\n            nn.LazyLinear(64),\n            nn.ReLU(),\n            nn.LazyLinear(5),\n            nn.LogSoftmax(dim=1)\n        )\n\n\n    def forward(self, input_X):\n        \n        for layer in self.extraction_layers:\n            input_X = layer(input_X)\n        \n        for layer in self.classification_layers:\n            input_X = layer(input_X)\n\n        return input_X","metadata":{"_uuid":"e7ac38aa-4331-44f9-a8ae-5fa0e93288b7","_cell_guid":"9a93b52f-33e6-491d-9142-cd784da11723","collapsed":false,"execution":{"iopub.status.busy":"2023-02-27T14:55:59.148016Z","iopub.execute_input":"2023-02-27T14:55:59.148735Z","iopub.status.idle":"2023-02-27T14:55:59.163555Z","shell.execute_reply.started":"2023-02-27T14:55:59.148701Z","shell.execute_reply":"2023-02-27T14:55:59.162397Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model:\n    def __init__(self):\n#         self.network = HybridNetwork()\n#         self.network = CNNNetwork()\n#         self.network = Time_Distributed_CNN_Network()\n#         self.network = AttnLSTM(input_size=64, hidden_size=128, num_layers=1)\n        self.network = AttnVGG(sample_size=64, num_classes=5)\n        \n        self.num_epochs = 20\n        self.batch_size = 16\n        self.grad_clipping = 10.0\n        self.optimizer_type = 'adamax'\n        self.lr = 0.001\n        self.num_output_units = 5\n\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.network.to(self.device)    \n\n        print('Device:', self.device)  \n\n        self.init_optimizer()\n        \n    def get_network(self):\n        return self.network\n\n    def init_optimizer(self):\n        parameters = [p for p in self.network.parameters() if p.requires_grad]\n        if self.optimizer_type == 'sgd':\n            self.optimizer = optim.SGD(parameters, self.lr,\n                                        momentum=0.4,\n                                        weight_decay=0)\n        elif self.optimizer_type == 'adamax':\n            self.optimizer = optim.Adamax(parameters,\n                                        lr=self.lr,\n                                        weight_decay=0)\n        else:\n            raise RuntimeError('Unsupported optimizer: %s' %\n                                self.optimizer_type)\n        self.scheduler = lr_scheduler.MultiStepLR(self.optimizer, milestones=[10, 15], gamma=0.5)\n\n\n    def normalize(self, X):\n        # apply standard normalization on x. mean = 0, std = 1\n        X = (X - np.mean(X)) / np.std(X)\n\n        return X\n\n\n    def reshape_image(self, input_X, label):\n        \n        '''choose one of the below according to the requirement'''\n        # for (16, 13, 64, 64)\n        X_full = input_X.reshape(input_X.shape[0], input_X.shape[1], input_X.shape[2], input_X.shape[3])\n        \n        # for (16, 1, 64, 64)\n        # X_full = input_X.reshape(input_X.shape[0], 1, input_X.shape[1], input_X.shape[2])\n        \n        # for attention lstm\n#         X_full = input_X.reshape(input_X.shape[0], input_X.shape[1]*input_X.shape[2], input_X.shape[3])\n        \n        # time distributed cnn\n#         X_full = input_X.reshape(input_X.shape[0], 8, 104, 64)\n#         X_full = np.expand_dims(X_full, axis=2)\n        \n        \n        y_full = np.eye(self.num_output_units)[label.astype(int)]\n\n        return X_full, y_full\n\n    def report_num_trainable_parameters(self):\n        num_parameters = 0\n        for p in self.network.parameters():\n            if p.requires_grad:\n                sz = list(p.size())\n\n                num_parameters += np.prod(sz)\n        print('Number of parameters: ', num_parameters)\n\n\n    def predict(self, test_data, test_label):\n        self.network.eval()\n\n        X = test_data\n        y = test_label\n\n        X = self.normalize(X)\n        cnt = 0\n\n        for X_batch, y_batch in tqdm(get_mini_batch(input_X=X, label=y, batch_size=self.batch_size), desc=\"Testing\"):\n\n            # reshape to appropriate format\n            X, y_true = self.reshape_image(X_batch, y_batch)\n\n            # convert to float32 and convert to torch tensor\n            X = X.astype(np.float32)\n            y_true = y_true.astype(np.float32)\n            X = torch.from_numpy(X)\n            y_true = torch.from_numpy(y_true)\n            \n            X = X.to(self.device)\n            y_true = y_true.to(self.device)\n\n            pred_proba = self.network(X)\n\n            y_pred = torch.argmax(pred_proba, dim=1)\n            y_true = torch.argmax(y_true, dim=1)\n            \n\n            cnt += torch.sum(y_pred == y_true).item()\n\n        print(f'accuracy: {cnt/test_data.shape[0]}')\n\n\n    def evaluate(self, validation_data, validation_label):\n        self.network.eval()\n\n        X = validation_data\n        y = validation_label\n\n        X = self.normalize(X)\n        cnt = 0\n\n        for X_batch, y_batch in tqdm(get_mini_batch(input_X=X, label=y, batch_size=self.batch_size), desc=\"Evaluating\"):\n\n            # reshape to appropriate format\n            X, y_true = self.reshape_image(X_batch, y_batch)\n\n            # convert to float32 and convert to torch tensor\n            X = X.astype(np.float32)\n            y_true = y_true.astype(np.float32)\n            X = torch.from_numpy(X)\n            y_true = torch.from_numpy(y_true)\n\n            X = X.to(self.device)\n            y_true = y_true.to(self.device)\n\n            pred_proba = self.network(X)\n\n            y_pred = torch.argmax(pred_proba, dim=1)\n            y_true = torch.argmax(y_true, dim=1)\n\n            cnt += torch.sum(y_pred == y_true).item()\n\n        print(f'accuracy: {cnt/validation_data.shape[0]}')\n\n\n    def train(self, input_X, label):\n        self.network.train()\n        \n        self.updates = 0\n        iter_cnt, num_iter = 0, (len(input_X) + self.batch_size - 1) // self.batch_size\n\n        for X_batch, y_batch in tqdm(get_mini_batch(input_X=input_X, label=label, batch_size=self.batch_size), desc=\"Training\"):\n\n            # reshape to appropriate format\n            X, y_true = self.reshape_image(X_batch, y_batch)\n\n            # convert to float32 and convert to torch tensor\n            X = X.astype(np.float32)\n            y_true = y_true.astype(np.float32)\n            X = torch.from_numpy(X)\n            y_true = torch.from_numpy(y_true)\n            \n            X = X.to(self.device)\n            y_true = y_true.to(self.device)\n\n            pred_proba = self.network(X)\n\n            loss = F.cross_entropy(pred_proba, y_true)\n            self.optimizer.zero_grad()\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(self.network.parameters(), self.grad_clipping)\n\n            # Update parameters\n            self.optimizer.step()\n\n            self.updates += 1\n            iter_cnt += 1\n\n        \n        print('Iter: %d/%d, Loss: %f' % (iter_cnt, num_iter, loss.item()))\n        self.scheduler.step()\n        print('LR:', self.scheduler.get_last_lr()[0])            \n\n\n    def fit(self, training_data, training_label, validation_data, validation_label):\n\n        X = training_data\n        y = training_label\n\n        X = self.normalize(X)\n\n        for epoch in range(self.num_epochs):\n            self.train(input_X=X, label=y)\n            print(\"Epoch: \", epoch)\n\n            self.evaluate(validation_data, validation_label)","metadata":{"_uuid":"0f22526d-cd67-43b2-9cef-e9a49cb355ee","_cell_guid":"ba90d8ec-b432-4268-9508-5e904066cab6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T15:39:22.200977Z","iopub.execute_input":"2023-02-27T15:39:22.201377Z","iopub.status.idle":"2023-02-27T15:39:22.229824Z","shell.execute_reply.started":"2023-02-27T15:39:22.201344Z","shell.execute_reply":"2023-02-27T15:39:22.228651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clear_cuda_memory():\n    import gc\n    # del model\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"_uuid":"18496de3-cce5-4e00-8eb8-0a93e52ffee9","_cell_guid":"f271c2eb-ceec-4e87-a8b7-da1ada1e925e","collapsed":false,"execution":{"iopub.status.busy":"2023-02-27T14:57:12.720437Z","iopub.execute_input":"2023-02-27T14:57:12.720830Z","iopub.status.idle":"2023-02-27T14:57:12.726057Z","shell.execute_reply.started":"2023-02-27T14:57:12.720799Z","shell.execute_reply":"2023-02-27T14:57:12.724956Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 1234\ntorch.manual_seed(seed)\nnp.random.seed(seed)","metadata":{"_uuid":"e48d12bf-089f-4535-98c0-74ae037b599d","_cell_guid":"f8f8088b-179d-4290-9295-c003e7723ee7","collapsed":false,"execution":{"iopub.status.busy":"2023-02-27T15:34:54.576690Z","iopub.execute_input":"2023-02-27T15:34:54.577048Z","iopub.status.idle":"2023-02-27T15:34:54.582134Z","shell.execute_reply.started":"2023-02-27T15:34:54.577019Z","shell.execute_reply":"2023-02-27T15:34:54.581138Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data, training_label, validation_data, validation_label, \\\n        test_data, test_label = train_val_split(images=images, labels=labels, \n                                    split_factor_train=0.8, split_factor_test=0.9)\n    \nprint(training_data.shape, training_label.shape, validation_data.shape, validation_label.shape, test_data.shape, test_label.shape)","metadata":{"_uuid":"98a4bba0-8db3-4780-bfd9-bceedd2fa628","_cell_guid":"baa81082-f74e-4292-998f-dc3239ed8f50","collapsed":false,"execution":{"iopub.status.busy":"2023-02-27T15:34:56.697658Z","iopub.execute_input":"2023-02-27T15:34:56.698727Z","iopub.status.idle":"2023-02-27T15:34:56.747855Z","shell.execute_reply.started":"2023-02-27T15:34:56.698693Z","shell.execute_reply":"2023-02-27T15:34:56.746676Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    \n    model = Model()\n    model.evaluate(validation_data, validation_label)\n    \n    model.fit(training_data, training_label, validation_data, validation_label)\n    \n    # save model\n    # torch.save(model, '/kaggle/working/checkpoint_cnn1.pt')\n    \n    torch.save(model.get_network().state_dict(), '/kaggle/working/checkpoint_attnLSTM.pt')\n\n\nclear_cuda_memory()    \nmain()","metadata":{"_uuid":"e07e189e-389a-499b-af72-bfe5b4e5de30","_cell_guid":"8ebc88fd-6150-4977-998a-14415b4fee83","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T15:35:08.800760Z","iopub.execute_input":"2023-02-27T15:35:08.801331Z","iopub.status.idle":"2023-02-27T15:36:48.340296Z","shell.execute_reply.started":"2023-02-27T15:35:08.801288Z","shell.execute_reply":"2023-02-27T15:36:48.339132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Testing by Loading Model**","metadata":{"_uuid":"a780286f-4826-4256-a83c-fdf4dadd76b4","_cell_guid":"61a40187-8c7c-4281-bef1-4acd016ada20","trusted":true}},{"cell_type":"code","source":"merged_data = np.append(validation_data, test_data, axis=0)\nmerged_data.shape\n\nmerged_label = np.append(validation_label, test_label, axis=0)\nmerged_label.shape","metadata":{"_uuid":"b0d2516e-c4e0-4eb0-a2ad-e7fa61b03716","_cell_guid":"858c51c3-7018-40dd-aade-85965d4dddd6","collapsed":false,"execution":{"iopub.status.busy":"2023-02-27T15:34:11.484223Z","iopub.execute_input":"2023-02-27T15:34:11.484962Z","iopub.status.idle":"2023-02-27T15:34:11.498457Z","shell.execute_reply.started":"2023-02-27T15:34:11.484918Z","shell.execute_reply":"2023-02-27T15:34:11.497231Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = torch.load('/kaggle/working/checkpoint_cnn.pt')\nmodel = Model()\nmodel.get_network().load_state_dict(torch.load('/kaggle/working/checkpoint_attnVGG.pt'))\n\n# seed = 1234\n# torch.manual_seed(seed)\n# np.random.seed(seed)\n\nmodel.predict(test_data, test_label)\nmodel.predict(validation_data, validation_label)\nmodel.predict(merged_data, merged_label)","metadata":{"_uuid":"ee59ec47-a56d-4ea9-80bf-85392561b70b","_cell_guid":"728854d5-2ec4-45d4-bf1a-b9ff446800c2","collapsed":false,"execution":{"iopub.status.busy":"2023-02-27T15:39:37.919162Z","iopub.execute_input":"2023-02-27T15:39:37.919863Z","iopub.status.idle":"2023-02-27T15:39:43.094218Z","shell.execute_reply.started":"2023-02-27T15:39:37.919826Z","shell.execute_reply":"2023-02-27T15:39:43.092772Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **End**","metadata":{"_uuid":"1415d4b9-8a06-4902-8776-4bb8f6807afb","_cell_guid":"791e3cd1-a2f9-41b3-af31-53f793ea638b","trusted":true}},{"cell_type":"code","source":"# rnn = nn.LSTM(input_size=49, hidden_size=10, num_layers=1, batch_first=True, dropout=0.25, bidirectional=True)\n# print(type(rnn))\n# input = torch.randn(16, 128, 7, 7)\n# print(input.shape)\n# flatten = nn.Flatten(start_dim=2, end_dim=3)\n# input = flatten(input)\n# print(input.shape)\n# output, (hn, cn) = rnn(input)\n# print(input)","metadata":{"_uuid":"e026db62-3489-4c64-8767-2859417b456f","_cell_guid":"2699afcf-1681-4cb1-aa3b-1c618b6a7fc6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training_data, training_label, validation_data, validation_label, test_data, test_label = train_val_split(images=images, labels=labels, split_factor=0.8, shuffle=True)\n# print(training_data.shape, training_label.shape, validation_data.shape, validation_label.shape, test_data.shape, test_label.shape)\n    \n# rnn = nn.LSTM(input_size=784, hidden_size=10, num_layers=1, batch_first=True, dropout=0.25, bidirectional=True)\n# input = training_data[:16]\n# input = input.astype(np.float32)\n# input = torch.from_numpy(input)\n# print(input.shape)\n# flatten = nn.Flatten(start_dim=2, end_dim=3)\n# input = flatten(input)\n# print(input.shape)\n# output, (hn, cn) = rnn(input)\n\n# print(output.shape)","metadata":{"_uuid":"581f5af5-a363-4b91-8112-7370fc784556","_cell_guid":"0aa209cf-c178-4073-a831-e9f5f0ce7e9f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x = torch.rand(16, 364, 28)\n# x = np.array(x).reshape(16,13, 28, 28)\n# x = np.expand_dims(x, axis=2)\n# x = torch.from_numpy(x)\n\n# model = TimeDistributed(module=nn.LazyConv2d(out_channels=64, kernel_size=3, padding=1), \n#                             time_steps=100)\n# output = model(x)\n\n# print(output.shape)","metadata":{"_uuid":"50671148-3994-499c-b38e-865d68205b20","_cell_guid":"f640ff83-5bd8-4b5e-9e54-f5c4dd2dba21","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}