{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Connect to Google Drive**","metadata":{}},{"cell_type":"code","source":"!pip install gdown\n\n# 64 x 64\n!gdown --folder 'https://drive.google.com/drive/folders/19MU_bHOWIPvCrcvHTBzHkvLbAFWt8ZOA'\n\n%cd /kaggle/working/64_64_gray_invert_dilate\n%ls","metadata":{"_uuid":"bf7ceb0f-6175-4269-a99e-dc79dbfdca17","_cell_guid":"739ed07e-61c0-4f85-b3dd-67a23cdec198","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T16:42:31.334603Z","iopub.execute_input":"2023-02-27T16:42:31.335290Z","iopub.status.idle":"2023-02-27T16:43:03.915290Z","shell.execute_reply.started":"2023-02-27T16:42:31.335255Z","shell.execute_reply":"2023-02-27T16:43:03.914096Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nRequirement already satisfied: gdown in /opt/conda/lib/python3.7/site-packages (4.6.4)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.28.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.11.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.64.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.7.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.11)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.3)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nRetrieving folder list\nProcessing file 1tuTRtM3R0DXhFwg3cTcXlTeOPYL0DuJt covid.npy\nProcessing file 1ZovHzOdPABmywo9ECaE97g8CDyz2CQ8u hb.npy\nProcessing file 1ZvfgjhuB0skNHcxkrIv5UGts_Zy5Hbih mi.npy\nProcessing file 1HW1u5MEhs5sg0oEv5zoffQ2zpD55_6jp normal.npy\nProcessing file 1bT7GDNlIblHiHlZTa2rYWdfUSGYLHeum pmi.npy\nRetrieving folder list completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom: https://drive.google.com/uc?id=1tuTRtM3R0DXhFwg3cTcXlTeOPYL0DuJt\nTo: /kaggle/working/64_64_gray_invert_dilate/64_64_gray_invert_dilate/covid.npy\n100%|███████████████████████████████████████| 13.3M/13.3M [00:00<00:00, 192MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1ZovHzOdPABmywo9ECaE97g8CDyz2CQ8u\nTo: /kaggle/working/64_64_gray_invert_dilate/64_64_gray_invert_dilate/hb.npy\n100%|███████████████████████████████████████| 38.0M/38.0M [00:00<00:00, 210MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1ZvfgjhuB0skNHcxkrIv5UGts_Zy5Hbih\nTo: /kaggle/working/64_64_gray_invert_dilate/64_64_gray_invert_dilate/mi.npy\n100%|██████████████████████████████████████| 16.7M/16.7M [00:00<00:00, 89.4MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1HW1u5MEhs5sg0oEv5zoffQ2zpD55_6jp\nTo: /kaggle/working/64_64_gray_invert_dilate/64_64_gray_invert_dilate/normal.npy\n100%|███████████████████████████████████████| 60.9M/60.9M [00:00<00:00, 193MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1bT7GDNlIblHiHlZTa2rYWdfUSGYLHeum\nTo: /kaggle/working/64_64_gray_invert_dilate/64_64_gray_invert_dilate/pmi.npy\n100%|███████████████████████████████████████| 17.4M/17.4M [00:00<00:00, 131MB/s]\nDownload completed\n/kaggle/working/64_64_gray_invert_dilate\n/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n\u001b[0m\u001b[01;34m64_64_gray_invert_dilate\u001b[0m/  covid.npy  hb.npy  mi.npy  normal.npy  pmi.npy\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Load Data**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport torch","metadata":{"_uuid":"eb6a5ebe-0906-4abc-8bb2-fe9cceede3f3","_cell_guid":"5cab276f-9f53-4c52-89cc-721e49c8f1c7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T16:43:03.918266Z","iopub.execute_input":"2023-02-27T16:43:03.919133Z","iopub.status.idle":"2023-02-27T16:43:03.926254Z","shell.execute_reply.started":"2023-02-27T16:43:03.919099Z","shell.execute_reply":"2023-02-27T16:43:03.925156Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"seed = 1234\ntorch.manual_seed(seed)\nnp.random.seed(seed)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T16:43:03.928407Z","iopub.execute_input":"2023-02-27T16:43:03.928751Z","iopub.status.idle":"2023-02-27T16:43:03.936843Z","shell.execute_reply.started":"2023-02-27T16:43:03.928723Z","shell.execute_reply":"2023-02-27T16:43:03.935820Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def get_mini_batch(input_X, label, batch_size):\n    for i in range(0, len(input_X), batch_size):\n        yield input_X[i: i + batch_size], label[i: i + batch_size]\n\ndef get_mini(input_X, batch_size):\n    for i in range(0, len(input_X), batch_size):\n        yield input_X[i: i + batch_size]","metadata":{"_uuid":"755b59cd-9f7f-4840-895a-ac48476ac74f","_cell_guid":"2bf8c125-2dc1-4388-9202-b168c8cce4d1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T16:43:03.939856Z","iopub.execute_input":"2023-02-27T16:43:03.940198Z","iopub.status.idle":"2023-02-27T16:43:03.948675Z","shell.execute_reply.started":"2023-02-27T16:43:03.940165Z","shell.execute_reply":"2023-02-27T16:43:03.947720Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def load_images_from_npy(divide=13):\n    covid_images = np.load('./covid.npy', allow_pickle=True)\n    hb_images = np.load('./hb.npy', allow_pickle=True)\n    mi_images = np.load('./mi.npy', allow_pickle=True)\n    normal_images = np.load('./normal.npy', allow_pickle=True)\n    pmi_images = np.load('./pmi.npy', allow_pickle=True)\n\n\n    # covid - 0\n    # hb - 1\n    # mi - 2\n    # normal - 3\n    # pmi - 4\n\n    # fill labels 0 for covid, 1 for hb, 2 for mi, 3 for normal, 4 for pmi\n    labels = [0] * (len(covid_images) // divide)\n    labels.extend([1] * (len(hb_images) // divide))\n    labels.extend([2] * (len(mi_images) // divide))\n    labels.extend([3] * (len(normal_images) // divide))\n    labels.extend([4] * (len(pmi_images) // divide))\n\n    images = np.concatenate((covid_images, hb_images, mi_images, normal_images, pmi_images), axis=0)\n\n    images = np.array(images)\n    labels = np.array(labels)\n\n    return images, labels\n\n\ndef take_12_leads(data, labels):\n    images = []\n    new_labels = []\n\n    for X, y in get_mini_batch(data, labels, 13):\n        X = np.delete(X, 4, axis=0)\n        y = np.delete(y, 4, axis=0)\n        images.extend(X)\n        new_labels.extend(y)\n\n    images = np.array(images)\n    new_labels = np.array(new_labels)\n    \n    return images, new_labels\n\ndef combine_leads_of_image(data, exclude_last=False):\n  \n    # store each 13 lead images in a list of 13*28*28 arrays\n    images = []\n\n    for X in get_mini(data, 13):\n        if exclude_last:\n            X = np.delete(X, 4, axis=0)\n        images.append(X)\n\n    images = np.array(images)\n    return images\n\n\ndef stack_images(images):\n    stacked_images = np.empty((images.shape[0],images.shape[1]*images.shape[2],images.shape[3]))\n\n    for i in range(images.shape[0]):\n        stacked_parts = np.vstack(images[i])\n        stacked_images[i] = stacked_parts\n    \n    return stacked_images","metadata":{"_uuid":"8b7616b6-27bf-48a4-9f6c-373eda5555ec","_cell_guid":"c3b3a5e7-8c22-49b4-ab34-50be71d28ba4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T16:43:03.950411Z","iopub.execute_input":"2023-02-27T16:43:03.950933Z","iopub.status.idle":"2023-02-27T16:43:03.965492Z","shell.execute_reply.started":"2023-02-27T16:43:03.950896Z","shell.execute_reply":"2023-02-27T16:43:03.964511Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"''' \ndivide = 1 for 35698 labels\ndivide = 13 for 2746 labels\n'''\nimages, labels = load_images_from_npy(divide=13)\nprint(images.shape, labels.shape, images[0].shape)\n\n'''combine 13 leads'''\nimages = combine_leads_of_image(images, exclude_last=False)\nprint(images.shape)","metadata":{"_uuid":"19a98488-9d71-4d46-b6f2-3da22eb91b90","_cell_guid":"aff4ae7e-a263-42a9-a748-f36a30ff0ca3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T16:43:03.966732Z","iopub.execute_input":"2023-02-27T16:43:03.967541Z","iopub.status.idle":"2023-02-27T16:43:04.194440Z","shell.execute_reply.started":"2023-02-27T16:43:03.967424Z","shell.execute_reply":"2023-02-27T16:43:04.193267Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"(35698, 64, 64) (2746,) (64, 64)\n(2746, 13, 64, 64)\n","output_type":"stream"}]},{"cell_type":"code","source":"# from PIL import Image, ImageOps, ImageFilter\n# from IPython.display import display\n\n# def build_image_from_array(img_arr):\n#     image = Image.fromarray(img_arr).convert('1')\n#     display(image)\n\n# build_image_from_array(images[0][4])","metadata":{"execution":{"iopub.status.busy":"2023-02-27T16:43:04.195906Z","iopub.execute_input":"2023-02-27T16:43:04.196588Z","iopub.status.idle":"2023-02-27T16:43:04.201469Z","shell.execute_reply.started":"2023-02-27T16:43:04.196546Z","shell.execute_reply":"2023-02-27T16:43:04.200397Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def train_val_split(images, labels, split_factor_train=0.8, split_factor_test=0.9):\n    random_indices = np.random.choice(len(images), len(images), replace=False)\n    training_data_full = images[random_indices]\n    training_label_full = labels[random_indices]\n\n    split_index_train = int(split_factor_train * len(training_data_full))\n    split_index_test = int(split_factor_test * len(training_data_full))\n\n    training_data = training_data_full[:split_index_train]\n    training_label = training_label_full[:split_index_train]\n\n    validation_data = training_data_full[split_index_train : split_index_test]\n    validation_label = training_label_full[split_index_train : split_index_test]\n\n    test_data = training_data_full[split_index_test :]\n    test_label = training_label_full[split_index_test :]\n\n    return training_data, training_label, validation_data, validation_label, test_data, test_label","metadata":{"_uuid":"55ce04c9-c7b9-48f2-bac5-52c0bad05666","_cell_guid":"867d4427-1005-4c63-a2ef-107e5f21ca9e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T16:43:04.203284Z","iopub.execute_input":"2023-02-27T16:43:04.203719Z","iopub.status.idle":"2023-02-27T16:43:04.214325Z","shell.execute_reply.started":"2023-02-27T16:43:04.203668Z","shell.execute_reply":"2023-02-27T16:43:04.213016Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"## **Build Model**","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport torch.optim.lr_scheduler as lr_scheduler","metadata":{"_uuid":"a306717b-64e1-4585-9adf-dcc51a879ceb","_cell_guid":"1930c221-3656-4496-b7ca-314758f89b14","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T16:43:04.215747Z","iopub.execute_input":"2023-02-27T16:43:04.216320Z","iopub.status.idle":"2023-02-27T16:43:04.225134Z","shell.execute_reply.started":"2023-02-27T16:43:04.216284Z","shell.execute_reply":"2023-02-27T16:43:04.224083Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## **CNN_with_Attention**","metadata":{}},{"cell_type":"code","source":"class ProjectorBlock(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(ProjectorBlock, self).__init__()\n        self.op = nn.Conv2d(in_channels=in_features, out_channels=out_features,\n            kernel_size=1, padding=0, bias=False)\n\n    def forward(self, x):\n        return self.op(x)\n\n\nclass SpatialAttn(nn.Module):\n    def __init__(self, in_features, normalize_attn=True):\n        super(SpatialAttn, self).__init__()\n        self.normalize_attn = normalize_attn\n        self.op = nn.Conv2d(in_channels=in_features, out_channels=1,\n            kernel_size=1, padding=0, bias=False)\n\n    def forward(self, l, g):\n        N, C, H, W = l.size()\n        c = self.op(l+g) # (batch_size,1,H,W)\n        if self.normalize_attn:\n            a = F.softmax(c.view(N,1,-1), dim=2).view(N,1,H,W)\n        else:\n            a = torch.sigmoid(c)\n        g = torch.mul(a.expand_as(l), l)\n        if self.normalize_attn:\n            g = g.view(N,C,-1).sum(dim=2) # (batch_size,C)\n        else:\n            g = F.adaptive_avg_pool2d(g, (1,1)).view(N,C)\n        return c.view(N,1,H,W), g\n\n    \n\nclass AttnVGG(nn.Module):\n    def __init__(self, sample_size, num_classes, attention=True, normalize_attn=True, init_weights=True):\n        super(AttnVGG, self).__init__()\n        # conv blocks\n        self.conv1 = self._make_layer(13, 64, 2)\n        self.conv2 = self._make_layer(64, 128, 2)\n        self.conv3 = self._make_layer(128, 256, 3)\n        self.conv4 = self._make_layer(256, 512, 3)\n        self.conv5 = self._make_layer(512, 512, 3)\n        self.conv6 = self._make_layer(512, 512, 2, pool=True)\n        self.dense = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=int(sample_size/32), padding=0, bias=True)\n        # attention blocks\n        self.attention = attention\n        if self.attention:\n            self.projector = ProjectorBlock(256, 512)\n            self.attn1 = SpatialAttn(in_features=512, normalize_attn=normalize_attn)\n            self.attn2 = SpatialAttn(in_features=512, normalize_attn=normalize_attn)\n            self.attn3 = SpatialAttn(in_features=512, normalize_attn=normalize_attn)\n        # final classification layer\n        if self.attention:\n            self.classify = nn.Linear(in_features=512*3, out_features=num_classes, bias=True)\n        else:\n            self.classify = nn.Linear(in_features=512, out_features=num_classes, bias=True)\n        # if init_weights:\n        #     self._initialize_weights()\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        l1 = self.conv3(x)\n        x = F.max_pool2d(l1, kernel_size=2, stride=2, padding=0)\n        l2 = self.conv4(x)\n        x = F.max_pool2d(l2, kernel_size=2, stride=2, padding=0)\n        l3 = self.conv5(x)\n        x = F.max_pool2d(l3, kernel_size=2, stride=2, padding=0)\n        x = self.conv6(x)\n        g = self.dense(x) # batch_sizex512x1x1\n\n        # attention\n        if self.attention:\n            c1, g1 = self.attn1(self.projector(l1), g)\n            c2, g2 = self.attn2(l2, g)\n            c3, g3 = self.attn3(l3, g)\n            g = torch.cat((g1,g2,g3), dim=1) # batch_sizex3C\n            # classification layer\n            x = self.classify(g) # batch_sizexnum_classes\n        else:\n            c1, c2, c3 = None, None, None\n            x = self.classify(torch.squeeze(g))\n        \n        return x\n\n    def _make_layer(self, in_features, out_features, blocks, pool=False):\n        layers = []\n        for i in range(blocks):\n            conv2d = nn.Conv2d(in_channels=in_features, out_channels=out_features, kernel_size=3, padding=1, bias=False)\n            layers += [conv2d, nn.BatchNorm2d(out_features), nn.ReLU(inplace=True)]\n            in_features = out_features\n            if pool:\n                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        return nn.Sequential(*layers)\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T16:43:04.230419Z","iopub.execute_input":"2023-02-27T16:43:04.230731Z","iopub.status.idle":"2023-02-27T16:43:04.255858Z","shell.execute_reply.started":"2023-02-27T16:43:04.230705Z","shell.execute_reply":"2023-02-27T16:43:04.254859Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"## **LSTM_with_Attention**","metadata":{}},{"cell_type":"code","source":"class TemporalAttn(nn.Module):\n    def __init__(self, hidden_size):\n        super(TemporalAttn, self).__init__()\n        self.hidden_size = hidden_size\n        self.fc1 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n        self.fc2 = nn.Linear(self.hidden_size*2, self.hidden_size, bias=False)\n\n    def forward(self, hidden_states):\n        score_first_part = self.fc1(hidden_states)\n        h_t = hidden_states[:,-1,:]\n        score = torch.bmm(score_first_part, h_t.unsqueeze(2)).squeeze(2)\n        attention_weights = F.softmax(score, dim=1)\n        context_vector = torch.bmm(hidden_states.permute(0,2,1), attention_weights.unsqueeze(2)).squeeze(2)\n        pre_activation = torch.cat((context_vector, h_t), dim=1)\n        attention_vector = self.fc2(pre_activation)\n        attention_vector = torch.tanh(attention_vector)\n\n        return attention_vector, attention_weights\n\n    \nclass AttnLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers):\n        super(AttnLSTM, self).__init__()\n        self.flatten = nn.Flatten(start_dim=1)\n        self.lstm = nn.LSTM(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True)\n        self.attn = TemporalAttn(hidden_size=hidden_size)\n        self.fc = nn.Linear(hidden_size, 5)\n\n    def forward(self, x):\n        x, (h_n, c_n) = self.lstm(x)\n        x, weights = self.attn(x)\n        x = self.fc(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2023-02-27T16:43:04.257559Z","iopub.execute_input":"2023-02-27T16:43:04.258309Z","iopub.status.idle":"2023-02-27T16:43:04.272035Z","shell.execute_reply.started":"2023-02-27T16:43:04.258272Z","shell.execute_reply":"2023-02-27T16:43:04.270824Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"## **Time_Distributed_CNN**","metadata":{}},{"cell_type":"code","source":"class TimeDistributed(nn.Module):\n    def __init__(self, module, time_steps, batch_first=False):\n        super(TimeDistributed, self).__init__()\n        self.module = module\n        \n        self.layers = nn.ModuleList([module for i in range(time_steps)])\n        \n        self.time_steps = time_steps\n        self.batch_first = batch_first\n\n    def forward(self, x):\n\n        batch_size, time_steps, channels, H, W = x.size()\n        output = torch.tensor([]).to(\"cuda:0\")\n        \n        for i in range(time_steps):\n            output_t = self.layers[i](x[:, i, :, :, :])\n            output_t  = output_t.unsqueeze(1)\n            output = torch.cat((output, output_t), 1)\n        \n        return output\n\nclass Time_Distributed_CNN_Network(nn.Module):\n    def __init__(self):\n        super(Time_Distributed_CNN_Network, self).__init__()\n\n        self.time_steps = 8\n        self.extraction_layers = nn.Sequential(\n            TimeDistributed(module=nn.LazyConv2d(out_channels=64, kernel_size=3, padding=1), \n                            time_steps=self.time_steps),\n            nn.ReLU(),\n            TimeDistributed(module=nn.MaxPool2d(kernel_size=2, stride=2), time_steps=self.time_steps),\n            \n            TimeDistributed(module=nn.LazyConv2d(out_channels=128, kernel_size=3, padding=1), \n                            time_steps=self.time_steps),\n            nn.ReLU(),\n            TimeDistributed(module=nn.MaxPool2d(kernel_size=2, stride=2), time_steps=self.time_steps),\n        )\n        \n        \n        self.classification_layers = nn.Sequential(\n            nn.Flatten(start_dim=1),\n            nn.LazyLinear(64),\n            nn.ReLU(),\n            nn.LazyLinear(5),\n            nn.LogSoftmax(dim=1)\n        )\n\n\n    def forward(self, input_X):\n        \n        for layer in self.extraction_layers:\n            input_X = layer(input_X)\n    \n        for layer in self.classification_layers:\n            input_X = layer(input_X)\n\n        return input_X","metadata":{"execution":{"iopub.status.busy":"2023-02-27T16:43:04.273784Z","iopub.execute_input":"2023-02-27T16:43:04.274167Z","iopub.status.idle":"2023-02-27T16:43:04.289530Z","shell.execute_reply.started":"2023-02-27T16:43:04.274133Z","shell.execute_reply":"2023-02-27T16:43:04.288611Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"## **CNN & LSTM_Attention Hybrid**","metadata":{}},{"cell_type":"code","source":"class HybridNetwork(nn.Module):\n    def __init__(self):\n        super(HybridNetwork, self).__init__()\n\n        self.extraction_layers = nn.Sequential(\n            nn.LazyConv2d(out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.LazyConv2d(out_channels=128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            nn.Flatten(start_dim=1, end_dim=2),\n        )\n        \n#         self.lstm = nn.GRU(input_size=16, hidden_size=10, num_layers=1, batch_first=True, \n#                                 dropout=0.25, bidirectional=False)\n        self.attn = AttnLSTM(input_size=16, hidden_size=128, num_layers=1)\n        \n        self.classification_layers = nn.Sequential(\n            nn.Flatten(start_dim=1),\n            nn.LazyLinear(64),\n            nn.ReLU(),\n            nn.LazyLinear(5),\n            nn.LogSoftmax(dim=1)\n        )\n\n\n    def forward(self, input_X):\n        \n        for layer in self.extraction_layers:\n            input_X = layer(input_X)\n        \n#         input_X, (h, c) = self.lstm(input_X) #lstm\n#         input_X, h = self.lstm(input_X) #gru\n        \n#         print('before attn', input_X.shape)\n        input_X = self.attn(input_X)\n        \n        for layer in self.classification_layers:\n            input_X = layer(input_X)\n\n        return input_X","metadata":{"_uuid":"16cd1521-2029-4927-8a3d-9980d216404e","_cell_guid":"d5a69bbf-7499-40a2-a47a-c9a6d112758b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T16:43:04.291417Z","iopub.execute_input":"2023-02-27T16:43:04.292129Z","iopub.status.idle":"2023-02-27T16:43:04.304565Z","shell.execute_reply.started":"2023-02-27T16:43:04.292093Z","shell.execute_reply":"2023-02-27T16:43:04.303523Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"## **CNN 2D**","metadata":{}},{"cell_type":"code","source":"class CNNNetwork(nn.Module):\n    def __init__(self):\n        super(CNNNetwork, self).__init__()\n\n        self.extraction_layers = nn.Sequential(\n            nn.LazyConv2d(out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.LazyConv2d(out_channels=128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.classification_layers = nn.Sequential(\n            nn.Flatten(start_dim=1),\n            nn.LazyLinear(64),\n            nn.ReLU(),\n            nn.LazyLinear(5),\n            nn.LogSoftmax(dim=1)\n        )\n\n\n    def forward(self, input_X):\n        \n        for layer in self.extraction_layers:\n            input_X = layer(input_X)\n        \n        for layer in self.classification_layers:\n            input_X = layer(input_X)\n\n        return input_X","metadata":{"execution":{"iopub.status.busy":"2023-02-27T16:43:04.305844Z","iopub.execute_input":"2023-02-27T16:43:04.306909Z","iopub.status.idle":"2023-02-27T16:43:04.320574Z","shell.execute_reply.started":"2023-02-27T16:43:04.306870Z","shell.execute_reply":"2023-02-27T16:43:04.319505Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"## **CNN 3D**","metadata":{}},{"cell_type":"code","source":"class CNN3DNetwork(nn.Module):\n    def __init__(self):\n        super(CNN3DNetwork, self).__init__()\n\n        \n        self.layers = nn.Sequential(\n            nn.LazyConv3d(out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool3d(kernel_size=2, stride=2),\n\n            nn.LazyConv3d(out_channels=128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool3d(kernel_size=2, stride=2),\n            \n            nn.LazyConv3d(out_channels=256, kernel_size=2, padding=1),\n            nn.ReLU(),\n            nn.MaxPool3d(kernel_size=2, stride=2),\n            \n            nn.LazyConv3d(out_channels=512, kernel_size=2, padding=1),\n            nn.ReLU(),\n            nn.MaxPool3d(kernel_size=2, stride=2),\n            \n            nn.LazyConv3d(out_channels=512, kernel_size=2, padding=1),\n            nn.ReLU(),\n            nn.MaxPool3d(kernel_size=2, stride=2),\n\n            nn.Flatten(start_dim=1),\n\n            nn.LazyLinear(128),\n            nn.ReLU(),\n            nn.LazyLinear(64),\n            nn.ReLU(),\n            nn.LazyLinear(5),\n            nn.LogSoftmax(dim=1)\n        )\n\n\n    def forward(self, input_X):\n\n      for layer in self.layers:\n        input_X = layer(input_X)\n        # print(input_X.shape)\n\n      return input_X","metadata":{"execution":{"iopub.status.busy":"2023-02-27T16:43:04.321634Z","iopub.execute_input":"2023-02-27T16:43:04.322257Z","iopub.status.idle":"2023-02-27T16:43:04.336386Z","shell.execute_reply.started":"2023-02-27T16:43:04.322221Z","shell.execute_reply":"2023-02-27T16:43:04.335510Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"class Model:\n    def __init__(self):\n#         self.network = HybridNetwork()\n#         self.network = CNNNetwork()\n#         self.network = Time_Distributed_CNN_Network()\n#         self.network = AttnLSTM(input_size=64, hidden_size=128, num_layers=1)\n#         self.network = AttnVGG(sample_size=64, num_classes=5)\n        self.network = CNN3DNetwork()\n        \n        self.num_epochs = 20\n        self.batch_size = 16\n        self.grad_clipping = 10.0\n        self.optimizer_type = 'adamax'\n        self.lr = 0.001\n        self.num_output_units = 5\n\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.network.to(self.device)    \n\n        print('Device:', self.device)  \n\n        self.init_optimizer()\n        \n    def get_network(self):\n        return self.network\n\n    def init_optimizer(self):\n        parameters = [p for p in self.network.parameters() if p.requires_grad]\n        if self.optimizer_type == 'sgd':\n            self.optimizer = optim.SGD(parameters, self.lr,\n                                        momentum=0.4,\n                                        weight_decay=0)\n        elif self.optimizer_type == 'adamax':\n            self.optimizer = optim.Adamax(parameters,\n                                        lr=self.lr,\n                                        weight_decay=0)\n        else:\n            raise RuntimeError('Unsupported optimizer: %s' %\n                                self.optimizer_type)\n        self.scheduler = lr_scheduler.MultiStepLR(self.optimizer, milestones=[10, 15], gamma=0.5)\n\n\n    def normalize(self, X):\n        # apply standard normalization on x. mean = 0, std = 1\n        X = (X - np.mean(X)) / np.std(X)\n\n        return X\n\n\n    def reshape_image(self, input_X, label):\n        \n        '''choose one of the below according to the requirement'''\n        # for cnn, attnvgg, hybrid\n#         X_full = input_X.reshape(input_X.shape[0], input_X.shape[1], input_X.shape[2], input_X.shape[3])\n        \n        # for cnn3D\n        X_full = input_X.reshape(input_X.shape[0], 1, input_X.shape[1], input_X.shape[2], input_X.shape[3])\n        \n        # for attn lstm\n#         X_full = input_X.reshape(input_X.shape[0], input_X.shape[1]*input_X.shape[2], input_X.shape[3])\n        \n        # time distributed cnn\n#         X_full = input_X.reshape(input_X.shape[0], 8, 104, 64)\n#         X_full = np.expand_dims(X_full, axis=2)\n        \n        \n        y_full = np.eye(self.num_output_units)[label.astype(int)]\n\n        return X_full, y_full\n\n    def report_num_trainable_parameters(self):\n        num_parameters = 0\n        for p in self.network.parameters():\n            if p.requires_grad:\n                sz = list(p.size())\n\n                num_parameters += np.prod(sz)\n        print('Number of parameters: ', num_parameters)\n\n\n    def predict(self, test_data, test_label):\n        self.network.eval()\n\n        X = test_data\n        y = test_label\n\n        X = self.normalize(X)\n        cnt = 0\n\n        for X_batch, y_batch in tqdm(get_mini_batch(input_X=X, label=y, batch_size=self.batch_size), desc=\"Testing\"):\n\n            # reshape to appropriate format\n            X, y_true = self.reshape_image(X_batch, y_batch)\n\n            # convert to float32 and convert to torch tensor\n            X = X.astype(np.float32)\n            y_true = y_true.astype(np.float32)\n            X = torch.from_numpy(X)\n            y_true = torch.from_numpy(y_true)\n            \n            X = X.to(self.device)\n            y_true = y_true.to(self.device)\n\n            pred_proba = self.network(X)\n\n            y_pred = torch.argmax(pred_proba, dim=1)\n            y_true = torch.argmax(y_true, dim=1)\n            \n\n            cnt += torch.sum(y_pred == y_true).item()\n\n        print(f'accuracy: {cnt/test_data.shape[0]}')\n\n\n    def evaluate(self, validation_data, validation_label):\n        self.network.eval()\n\n        X = validation_data\n        y = validation_label\n\n        X = self.normalize(X)\n        cnt = 0\n\n        for X_batch, y_batch in tqdm(get_mini_batch(input_X=X, label=y, batch_size=self.batch_size), desc=\"Evaluating\"):\n\n            # reshape to appropriate format\n            X, y_true = self.reshape_image(X_batch, y_batch)\n\n            # convert to float32 and convert to torch tensor\n            X = X.astype(np.float32)\n            y_true = y_true.astype(np.float32)\n            X = torch.from_numpy(X)\n            y_true = torch.from_numpy(y_true)\n\n            X = X.to(self.device)\n            y_true = y_true.to(self.device)\n\n            pred_proba = self.network(X)\n\n            y_pred = torch.argmax(pred_proba, dim=1)\n            y_true = torch.argmax(y_true, dim=1)\n\n            cnt += torch.sum(y_pred == y_true).item()\n\n        print(f'accuracy: {cnt/validation_data.shape[0]}')\n\n\n    def train(self, input_X, label):\n        self.network.train()\n        \n        self.updates = 0\n        iter_cnt, num_iter = 0, (len(input_X) + self.batch_size - 1) // self.batch_size\n\n        for X_batch, y_batch in tqdm(get_mini_batch(input_X=input_X, label=label, batch_size=self.batch_size), desc=\"Training\"):\n\n            # reshape to appropriate format\n            X, y_true = self.reshape_image(X_batch, y_batch)\n\n            # convert to float32 and convert to torch tensor\n            X = X.astype(np.float32)\n            y_true = y_true.astype(np.float32)\n            X = torch.from_numpy(X)\n            y_true = torch.from_numpy(y_true)\n            \n            X = X.to(self.device)\n            y_true = y_true.to(self.device)\n\n            pred_proba = self.network(X)\n\n            loss = F.cross_entropy(pred_proba, y_true)\n            self.optimizer.zero_grad()\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(self.network.parameters(), self.grad_clipping)\n\n            # Update parameters\n            self.optimizer.step()\n\n            self.updates += 1\n            iter_cnt += 1\n\n        \n        print('Iter: %d/%d, Loss: %f' % (iter_cnt, num_iter, loss.item()))\n        self.scheduler.step()\n        print('LR:', self.scheduler.get_last_lr()[0])            \n\n\n    def fit(self, training_data, training_label, validation_data, validation_label):\n\n        X = training_data\n        y = training_label\n\n        X = self.normalize(X)\n\n        for epoch in range(self.num_epochs):\n            self.train(input_X=X, label=y)\n            print(\"Epoch: \", epoch)\n\n            self.evaluate(validation_data, validation_label)","metadata":{"_uuid":"e975160e-9c98-4993-81af-baea782681ae","_cell_guid":"76e65e53-13d6-4053-878a-06cb4fb1d8e7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T16:43:04.337801Z","iopub.execute_input":"2023-02-27T16:43:04.338313Z","iopub.status.idle":"2023-02-27T16:43:04.367699Z","shell.execute_reply.started":"2023-02-27T16:43:04.338277Z","shell.execute_reply":"2023-02-27T16:43:04.366789Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def clear_cuda_memory():\n    import gc\n    # del model\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-02-27T16:43:04.368877Z","iopub.execute_input":"2023-02-27T16:43:04.369242Z","iopub.status.idle":"2023-02-27T16:43:04.383316Z","shell.execute_reply.started":"2023-02-27T16:43:04.369206Z","shell.execute_reply":"2023-02-27T16:43:04.382245Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"training_data, training_label, validation_data, validation_label, \\\n    test_data, test_label = train_val_split(images=images, labels=labels, \n                                split_factor_train=0.8, split_factor_test=0.9)\n\nprint(training_data.shape, training_label.shape, validation_data.shape, validation_label.shape, test_data.shape, test_label.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T16:43:04.384660Z","iopub.execute_input":"2023-02-27T16:43:04.385517Z","iopub.status.idle":"2023-02-27T16:43:04.439928Z","shell.execute_reply.started":"2023-02-27T16:43:04.385456Z","shell.execute_reply":"2023-02-27T16:43:04.438853Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"(2196, 13, 64, 64) (2196,) (275, 13, 64, 64) (275,) (275, 13, 64, 64) (275,)\n","output_type":"stream"}]},{"cell_type":"code","source":"def main():\n    \n    model = Model()\n    model.evaluate(validation_data, validation_label)\n    \n    model.fit(training_data, training_label, validation_data, validation_label)\n    \n    # save model\n    # torch.save(model, '/kaggle/working/checkpoint_cnn1.pt')\n    \n    torch.save(model.get_network().state_dict(), '/kaggle/working/checkpoint_CNN3D.pt')\n\n\nclear_cuda_memory()    \nmain()","metadata":{"_uuid":"e4aaffbe-8435-4d5c-bd50-7a15f3ffda75","_cell_guid":"30117813-1e4c-4443-bb3d-b7fa332efa76","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-27T16:43:04.441134Z","iopub.execute_input":"2023-02-27T16:43:04.441426Z","iopub.status.idle":"2023-02-27T16:47:00.550404Z","shell.execute_reply.started":"2023-02-27T16:43:04.441398Z","shell.execute_reply":"2023-02-27T16:47:00.549381Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 31.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.09090909090909091\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:10, 12.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.153159\nLR: 0.001\nEpoch:  0\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.6290909090909091\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:11, 12.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.292122\nLR: 0.001\nEpoch:  1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 34.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.7890909090909091\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:11, 12.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.021763\nLR: 0.001\nEpoch:  2\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.96\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:11, 12.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000309\nLR: 0.001\nEpoch:  3\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9018181818181819\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:11, 12.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000208\nLR: 0.001\nEpoch:  4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9781818181818182\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:10, 12.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000003\nLR: 0.001\nEpoch:  5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 36.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9709090909090909\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:10, 12.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000010\nLR: 0.001\nEpoch:  6\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 36.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9636363636363636\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:10, 12.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000006\nLR: 0.001\nEpoch:  7\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9709090909090909\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:10, 12.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000001\nLR: 0.001\nEpoch:  8\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9709090909090909\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:11, 12.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000046\nLR: 0.0005\nEpoch:  9\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9781818181818182\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:11, 12.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000025\nLR: 0.0005\nEpoch:  10\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9781818181818182\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:11, 12.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000001\nLR: 0.0005\nEpoch:  11\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9854545454545455\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:11, 12.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000066\nLR: 0.0005\nEpoch:  12\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9745454545454545\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:11, 12.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000042\nLR: 0.0005\nEpoch:  13\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9745454545454545\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:11, 12.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000055\nLR: 0.00025\nEpoch:  14\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9745454545454545\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:11, 12.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000000\nLR: 0.00025\nEpoch:  15\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9854545454545455\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:11, 12.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000000\nLR: 0.00025\nEpoch:  16\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9854545454545455\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:11, 12.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000000\nLR: 0.00025\nEpoch:  17\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9854545454545455\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:11, 12.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000000\nLR: 0.00025\nEpoch:  18\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9854545454545455\n","output_type":"stream"},{"name":"stderr","text":"Training: 138it [00:11, 12.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iter: 138/138, Loss: 0.000000\nLR: 0.00025\nEpoch:  19\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 18it [00:00, 35.84it/s]","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9854545454545455\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Testing by Loading Model**","metadata":{}},{"cell_type":"code","source":"# model = torch.load('/kaggle/working/checkpoint_cnn.pt')\nmodel = Model()\nmodel.get_network().load_state_dict(torch.load('/kaggle/working/checkpoint_CNN3D.pt'))\n\nmodel.predict(test_data, test_label)\n\nmodel.predict(validation_data, validation_label)\n\ntest_data_concated = np.append(test_data, validation_data, axis = 0)\ntest_label_concated = np.append(test_label, validation_label, axis = 0)\nprint(test_data_concated.shape)\nprint(test_label_concated.shape)\n\nmodel.predict(test_data_concated, test_label_concated)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T16:47:29.072469Z","iopub.execute_input":"2023-02-27T16:47:29.073534Z","iopub.status.idle":"2023-02-27T16:47:31.704886Z","shell.execute_reply.started":"2023-02-27T16:47:29.073485Z","shell.execute_reply":"2023-02-27T16:47:31.703849Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Testing: 18it [00:00, 31.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9927272727272727\n","output_type":"stream"},{"name":"stderr","text":"Testing: 18it [00:00, 36.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9854545454545455\n(550, 13, 64, 64)\n(550,)\n","output_type":"stream"},{"name":"stderr","text":"Testing: 35it [00:01, 34.72it/s]","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9890909090909091\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **End**","metadata":{}},{"cell_type":"code","source":"# rnn = nn.LSTM(input_size=49, hidden_size=10, num_layers=1, batch_first=True, dropout=0.25, bidirectional=True)\n# print(type(rnn))\n# input = torch.randn(16, 128, 7, 7)\n# print(input.shape)\n# flatten = nn.Flatten(start_dim=2, end_dim=3)\n# input = flatten(input)\n# print(input.shape)\n# output, (hn, cn) = rnn(input)\n# print(input)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T16:47:02.525116Z","iopub.execute_input":"2023-02-27T16:47:02.527358Z","iopub.status.idle":"2023-02-27T16:47:02.533307Z","shell.execute_reply.started":"2023-02-27T16:47:02.527321Z","shell.execute_reply":"2023-02-27T16:47:02.532223Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# training_data, training_label, validation_data, validation_label, test_data, test_label = train_val_split(images=images, labels=labels, split_factor=0.8, shuffle=True)\n# print(training_data.shape, training_label.shape, validation_data.shape, validation_label.shape, test_data.shape, test_label.shape)\n    \n# rnn = nn.LSTM(input_size=784, hidden_size=10, num_layers=1, batch_first=True, dropout=0.25, bidirectional=True)\n# input = training_data[:16]\n# input = input.astype(np.float32)\n# input = torch.from_numpy(input)\n# print(input.shape)\n# flatten = nn.Flatten(start_dim=2, end_dim=3)\n# input = flatten(input)\n# print(input.shape)\n# output, (hn, cn) = rnn(input)\n\n# print(output.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T16:47:02.537977Z","iopub.execute_input":"2023-02-27T16:47:02.539604Z","iopub.status.idle":"2023-02-27T16:47:02.546890Z","shell.execute_reply.started":"2023-02-27T16:47:02.539568Z","shell.execute_reply":"2023-02-27T16:47:02.545932Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# x = torch.rand(16, 364, 28)\n# x = np.array(x).reshape(16,13, 28, 28)\n# x = np.expand_dims(x, axis=2)\n# x = torch.from_numpy(x)\n\n# model = TimeDistributed(module=nn.LazyConv2d(out_channels=64, kernel_size=3, padding=1), \n#                             time_steps=100)\n# output = model(x)\n\n# print(output.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T16:47:02.549007Z","iopub.execute_input":"2023-02-27T16:47:02.550142Z","iopub.status.idle":"2023-02-27T16:47:02.560250Z","shell.execute_reply.started":"2023-02-27T16:47:02.550108Z","shell.execute_reply":"2023-02-27T16:47:02.559187Z"},"trusted":true},"execution_count":52,"outputs":[]}]}